{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychoi-kr/langchain-book/blob/main/chapter5/5_2_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 보안 비밀에 OpenAI API 키를 등록한 경우\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "M13h9QsoqGhY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WqgjYwQUemjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be616ec6-c560-42f2-d19a-2e546283e781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.19\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.16.2\n",
            "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai==0.1.1\n",
            "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
            "Collecting langchain-experimental==0.0.56\n",
            "  Downloading langchain_experimental-0.0.56-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchainhub==0.1.15\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.19)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain==0.1.19)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain==0.1.19)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.19)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.19)\n",
            "  Downloading langsmith-0.1.59-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.16.2) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.16.2)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (4.11.0)\n",
            "Collecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.1)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub==0.1.15)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.16.2) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.16.2) (1.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.16.2) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.16.2)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.16.2)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.1) (2023.12.25)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: types-requests, packaging, orjson, mypy-extensions, jsonpointer, h11, typing-inspect, tiktoken, marshmallow, langchainhub, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-text-splitters, langchain-openai, langchain-community, langchain, langchain-experimental\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.6 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-experimental-0.0.56 langchain-openai-0.1.1 langchain-text-splitters-0.0.2 langchainhub-0.1.15 langsmith-0.1.59 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.16.2 orjson-3.10.3 packaging-23.2 tiktoken-0.7.0 types-requests-2.31.0.20240406 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.19 openai==1.16.2 langchain-openai==0.1.1 langchain-experimental==0.0.56 langchainhub==0.1.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4Fz0OFVZmSq"
      },
      "source": [
        "## 5-2 Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HSybywiZn6c"
      },
      "source": [
        "### Agents 사용 예"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_1RES8TRp1GX"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "\n",
        "langchain.verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qlRHx6ejZBbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e518d5-7995-4546-b1dc-db2a67b611da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI can use the terminal to list the files in the sample_data directory.\n",
            "Action: terminal\n",
            "Action Input: ls sample_data\u001b[0mExecuting command:\n",
            " ls sample_data\n",
            "\u001b[36;1m\u001b[1;3manscombe.json\n",
            "california_housing_test.csv\n",
            "california_housing_train.csv\n",
            "mnist_test.csv\n",
            "mnist_train_small.csv\n",
            "README.md\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI now know the files in the sample_data directory.\n",
            "Final Answer: anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], allow_dangerous_tools=True)\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"output\"])"
      ],
      "metadata": {
        "id": "kTodBr7Wiw8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65218dc-d653-47f2-a37c-28bb8547476f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U2AKd4BsSEt"
      },
      "source": [
        "### Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pvJUF7XogVRI"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "def my_super_func(param):\n",
        "    return \"42\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=my_super_func,\n",
        "        name=\"The_Answer\",\n",
        "        description=\"생명, 우주, 그리고 모든 것에 대한 궁극적인 질문의 답\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MoEjpv2XtemN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8423c4-b11c-4744-e3ad-2d78826385d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should seek the ultimate answer to the truth of this world\n",
            "Action: The_Answer\n",
            "Action Input: 이 세계의 진리\u001b[0m\u001b[36;1m\u001b[1;3m42\u001b[0m\u001b[32;1m\u001b[1;3mThis answer seems to be a reference to the Hitchhiker's Guide to the Galaxy, but it may not be the ultimate truth.\n",
            "Action: The_Answer\n",
            "Action Input: 이 세계의 진리\u001b[0m\u001b[36;1m\u001b[1;3m42\u001b[0m\u001b[32;1m\u001b[1;3mI need to keep searching for the ultimate answer to the truth of this world\n",
            "Action: The_Answer\n",
            "Action Input: 이 세계의 진리\u001b[0m\u001b[36;1m\u001b[1;3m42\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 생명, 우주, 그리고 모든 것에 대한 궁극적인 질문의 답\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '이 세계의 진리를 알려주세요', 'output': '생명, 우주, 그리고 모든 것에 대한 궁극적인 질문의 답'}\n"
          ]
        }
      ],
      "source": [
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "result = agent_executor.invoke({\"input\": \"이 세계의 진리를 알려주세요\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MFW6L4Dbtkpv",
        "outputId": "e9a397e7-5338-419e-b45a-1d9fc12f23c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "summarize_template = \"\"\"아래의 글을 결론만 한 마디로 요약해 주세요.\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=summarize_chain.run,\n",
        "        name=\"Summarizer\",\n",
        "        description=\"Text summarizer\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kAjRYZTLv7nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2c687b-990f-47a3-995c-153ad54cf622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the Summarizer tool to summarize the text provided in Korean.\n",
            "Action: Summarizer\n",
            "Action Input: 안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m아래의 글을 결론만 한 마디로 요약해 주세요.\n",
            "\n",
            "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mChatGPT는 OpenAI가 개발한 AI 언어 모델로, 다양한 주제에 대한 질문에 답하거나 대화를 나누는 것을 전문으로 합니다.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: ChatGPT는 OpenAI가 개발한 AI 언어 모델로, 다양한 주제에 대한 질문에 답하거나 대화를 나누는 것을 전문으로 합니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '다음을 요약해 주세요.\\n\\n안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\\n제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\\n질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.', 'output': 'ChatGPT는 OpenAI가 개발한 AI 언어 모델로, 다양한 주제에 대한 질문에 답하거나 대화를 나누는 것을 전문으로 합니다.'}\n"
          ]
        }
      ],
      "source": [
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "text = \"\"\"다음을 요약해 주세요.\n",
        "\n",
        "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\n",
        "제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\n",
        "질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"\"\"\n",
        "\n",
        "result = agent_executor.invoke({\"input\": text})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bTNTRGNZNM"
      },
      "source": [
        "### Function calling을 사용하는 OpenAI Functions Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XP8Nm_1d6zZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d706ecd-d209-4274-b628-f7deca2160ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `terminal` with `{'commands': 'ls sample_data'}`\n",
            "\n",
            "\n",
            "\u001b[0mExecuting command:\n",
            " ['ls sample_data']\n",
            "\u001b[36;1m\u001b[1;3manscombe.json\n",
            "california_housing_test.csv\n",
            "california_housing_train.csv\n",
            "mnist_test.csv\n",
            "mnist_train_small.csv\n",
            "README.md\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m`sample_data` 디렉터리에 있는 파일 목록은 다음과 같습니다:\n",
            "- anscombe.json\n",
            "- california_housing_test.csv\n",
            "- california_housing_train.csv\n",
            "- mnist_test.csv\n",
            "- mnist_train_small.csv\n",
            "- README.md\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'sample_data 디렉터리에 있는 파일 목록을 알려줘',\n",
              " 'output': '`sample_data` 디렉터리에 있는 파일 목록은 다음과 같습니다:\\n- anscombe.json\\n- california_housing_test.csv\\n- california_housing_train.csv\\n- mnist_test.csv\\n- mnist_train_small.csv\\n- README.md'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], allow_dangerous_tools=True)\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "\n",
        "agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV6Mx0TUO_hT"
      },
      "source": [
        "### 여러 도구를 한 번에 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bJTSM5gIPDOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a28ae04-7f1b-4782-bb6c-751461fa5559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckduckgo_search\n",
            "  Downloading duckduckgo_search-6.1.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search) (8.1.7)\n",
            "Collecting pyreqwest-impersonate>=0.4.5 (from duckduckgo_search)\n",
            "  Downloading pyreqwest_impersonate-0.4.5-cp38-abi3-manylinux_2_28_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search) (3.10.3)\n",
            "Installing collected packages: pyreqwest-impersonate, duckduckgo_search\n",
            "Successfully installed duckduckgo_search-6.1.0 pyreqwest-impersonate-0.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install duckduckgo_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uJAM26YzQQOa"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "\n",
        "langchain.debug = True\n",
        "langchain.verbose = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EgUyIpfrNq1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69116919-e8cc-4ec2-de62-3ac687aed37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [11ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [893ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"function_call\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"arguments\": \"{\\\"query\\\":\\\"서울 날씨\\\"}\",\n",
            "                \"name\": \"duckduckgo_search\"\n",
            "              }\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"function_call\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-6e5d725f-d41a-4769-a01b-3d116c5a6315\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [920ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': '서울 날씨'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [982ms] Exiting Tool run with output:\n",
            "\u001b[0m\"부분적으로 흐린 날씨 바람: 산들 바람 , 북서 , 속도 4 초당 미터 돌풍: 11 초당 미터 상대 습도: 40% 흐림: 22% 기압: 1004 고전력 증폭기 자외선 지수: 3,9 (보통) 가시성: 100% 온통 눈 세상 대관령. (평창=연합뉴스) 유형재 기자 = 전날 내린 폭설로 설국이 된 강원 평창군 대관령 일원에 13일 관광객들이 찾아와 겨울 낭만을 만끽하고 있다. 2023.12.13 yoo21@yna.co.kr. (서울=연합뉴스) 이미령 기자 = 토요일인 16일 기온이 뚝 떨어져 춥고 서쪽 ... 현재 서울 기온 영하 6.3도, 천안은 영하 10.4도를 보이고 있고 한파경보가 발효 중인 대관령은 영하 12.3도까지 기온이 떨어져 있습니다. 최근 눈이 ... 아침 최저기온은 -18∼-3도, 낮 최고기온은 -4∼4도로 예보됐다. 서울을 비롯한 수도권과 중부 지방은 한낮에도 영하권을 맴돌겠다. ADVERTISEMENT. ADVERTISEMENT. 면역력이 약한 노약자와 어린이는 가급적 야외활동을 자제하는 등 급격한 기온 변화와 낮은 기온으로 인한 ... 기상청은 금요일인 17일 전국날씨 낮최고기온 서울 25도, 대전 26도, 광주 25도, 대구 28도, 부산 24도, 제주도 26도를 기록하며 봄날씨예보했다.서울날씨는 17일은 가끔 구름많다가 낮부터 점차 맑아지겠다. 18일 가끔 구름 많겠다.17일 아침까지 기온은 평년(최저 9~14도, 최고 21~24도)과 비슷하거나 조금 ...\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [5ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [9ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\\nAI: {'arguments': '{\\\"query\\\":\\\"서울 날씨\\\"}', 'name': 'duckduckgo_search'}\\nFunction: 부분적으로 흐린 날씨 바람: 산들 바람 , 북서 , 속도 4 초당 미터 돌풍: 11 초당 미터 상대 습도: 40% 흐림: 22% 기압: 1004 고전력 증폭기 자외선 지수: 3,9 (보통) 가시성: 100% 온통 눈 세상 대관령. (평창=연합뉴스) 유형재 기자 = 전날 내린 폭설로 설국이 된 강원 평창군 대관령 일원에 13일 관광객들이 찾아와 겨울 낭만을 만끽하고 있다. 2023.12.13 yoo21@yna.co.kr. (서울=연합뉴스) 이미령 기자 = 토요일인 16일 기온이 뚝 떨어져 춥고 서쪽 ... 현재 서울 기온 영하 6.3도, 천안은 영하 10.4도를 보이고 있고 한파경보가 발효 중인 대관령은 영하 12.3도까지 기온이 떨어져 있습니다. 최근 눈이 ... 아침 최저기온은 -18∼-3도, 낮 최고기온은 -4∼4도로 예보됐다. 서울을 비롯한 수도권과 중부 지방은 한낮에도 영하권을 맴돌겠다. ADVERTISEMENT. ADVERTISEMENT. 면역력이 약한 노약자와 어린이는 가급적 야외활동을 자제하는 등 급격한 기온 변화와 낮은 기온으로 인한 ... 기상청은 금요일인 17일 전국날씨 낮최고기온 서울 25도, 대전 26도, 광주 25도, 대구 28도, 부산 24도, 제주도 26도를 기록하며 봄날씨예보했다.서울날씨는 17일은 가끔 구름많다가 낮부터 점차 맑아지겠다. 18일 가끔 구름 많겠다.17일 아침까지 기온은 평년(최저 9~14도, 최고 21~24도)과 비슷하거나 조금 ...\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [508ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"function_call\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"arguments\": \"{\\\"query\\\":\\\"부산 날씨\\\"}\",\n",
            "                \"name\": \"duckduckgo_search\"\n",
            "              }\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"function_call\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-b9479d04-f397-4d67-b62b-3388caa95207\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [530ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': '부산 날씨'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [1.23s] Exiting Tool run with output:\n",
            "\u001b[0m\"부산 광역시 (Busan) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 Ventusky: 지도상 일기예보 소개 부산광역시 가야동 수영 동래 화명동 김해시 기장 김해시 일광 양산시 산본 장안 양산시 통신동 창원시 양산시 삼랑진 내광 온양읍 창원시 거제시 남창 삼광 마산시 온산읍 산양 신현 진동면 서상리 내소 진동리 밀양시 부산 진북면 격동 대전 울산광역시 산내면 ... (부산·경남=뉴스1) 한송학 기자 | 19일 부산·경남은 대체로 맑고 기온이 30도 이상으로 오르는 곳이 있겠다.기상청에 따르면 이날 아침 최저기온은 부산 17도, 창원 14도, ... [오늘의 날씨] 부산·경남(19일, 일)…맑고 낮 기온 30도까지 ... [날씨] 부산 내일도 온화해요…내일 아침까지 안개 주의 ... 뉴스7(부산) 온화한 날씨가 이어지고 있습니다. 내일도 마찬가지로 추위로 인한 불편함은 없겠습니다. 아침 기온 부산은 3도 안팎으로, 오늘과 비슷하게 시작하겠고요. 19일 부산지역은 대체로 맑은 날씨가 될 것으로 부산기상청은 예보했다. 이날 낮 최고기온은 26도, 20일 아침 최저기온은 17도로 예상됐다.\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [7ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [12ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\\nAI: {'arguments': '{\\\"query\\\":\\\"서울 날씨\\\"}', 'name': 'duckduckgo_search'}\\nFunction: 부분적으로 흐린 날씨 바람: 산들 바람 , 북서 , 속도 4 초당 미터 돌풍: 11 초당 미터 상대 습도: 40% 흐림: 22% 기압: 1004 고전력 증폭기 자외선 지수: 3,9 (보통) 가시성: 100% 온통 눈 세상 대관령. (평창=연합뉴스) 유형재 기자 = 전날 내린 폭설로 설국이 된 강원 평창군 대관령 일원에 13일 관광객들이 찾아와 겨울 낭만을 만끽하고 있다. 2023.12.13 yoo21@yna.co.kr. (서울=연합뉴스) 이미령 기자 = 토요일인 16일 기온이 뚝 떨어져 춥고 서쪽 ... 현재 서울 기온 영하 6.3도, 천안은 영하 10.4도를 보이고 있고 한파경보가 발효 중인 대관령은 영하 12.3도까지 기온이 떨어져 있습니다. 최근 눈이 ... 아침 최저기온은 -18∼-3도, 낮 최고기온은 -4∼4도로 예보됐다. 서울을 비롯한 수도권과 중부 지방은 한낮에도 영하권을 맴돌겠다. ADVERTISEMENT. ADVERTISEMENT. 면역력이 약한 노약자와 어린이는 가급적 야외활동을 자제하는 등 급격한 기온 변화와 낮은 기온으로 인한 ... 기상청은 금요일인 17일 전국날씨 낮최고기온 서울 25도, 대전 26도, 광주 25도, 대구 28도, 부산 24도, 제주도 26도를 기록하며 봄날씨예보했다.서울날씨는 17일은 가끔 구름많다가 낮부터 점차 맑아지겠다. 18일 가끔 구름 많겠다.17일 아침까지 기온은 평년(최저 9~14도, 최고 21~24도)과 비슷하거나 조금 ...\\nAI: {'arguments': '{\\\"query\\\":\\\"부산 날씨\\\"}', 'name': 'duckduckgo_search'}\\nFunction: 부산 광역시 (Busan) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 Ventusky: 지도상 일기예보 소개 부산광역시 가야동 수영 동래 화명동 김해시 기장 김해시 일광 양산시 산본 장안 양산시 통신동 창원시 양산시 삼랑진 내광 온양읍 창원시 거제시 남창 삼광 마산시 온산읍 산양 신현 진동면 서상리 내소 진동리 밀양시 부산 진북면 격동 대전 울산광역시 산내면 ... (부산·경남=뉴스1) 한송학 기자 | 19일 부산·경남은 대체로 맑고 기온이 30도 이상으로 오르는 곳이 있겠다.기상청에 따르면 이날 아침 최저기온은 부산 17도, 창원 14도, ... [오늘의 날씨] 부산·경남(19일, 일)…맑고 낮 기온 30도까지 ... [날씨] 부산 내일도 온화해요…내일 아침까지 안개 주의 ... 뉴스7(부산) 온화한 날씨가 이어지고 있습니다. 내일도 마찬가지로 추위로 인한 불편함은 없겠습니다. 아침 기온 부산은 3도 안팎으로, 오늘과 비슷하게 시작하겠고요. 19일 부산지역은 대체로 맑은 날씨가 될 것으로 부산기상청은 예보했다. 이날 낮 최고기온은 26도, 20일 아침 최저기온은 17도로 예상됐다.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [3.12s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"서울과 부산의 현재 날씨는 다음과 같습니다:\\n\\n### 서울\\n- **기온**: 영하 6.3도\\n- **날씨**: 부분적으로 흐림\\n- **바람**: 산들 바람, 북서, 속도 4 m/s, 돌풍 11 m/s\\n- **습도**: 40%\\n- **기압**: 1004 hPa\\n- **자외선 지수**: 3.9 (보통)\\n- **가시성**: 100%\\n\\n### 부산\\n- **기온**: 아침 최저기온 17도, 낮 최고기온 26도\\n- **날씨**: 대체로 맑음\\n- **바람**: 온화한 날씨가 이어지고 있으며, 추위로 인한 불편함은 없음\\n\\n서울은 현재 매우 추운 날씨를 보이고 있으며, 부산은 비교적 온화한 날씨를 유지하고 있습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"서울과 부산의 현재 날씨는 다음과 같습니다:\\n\\n### 서울\\n- **기온**: 영하 6.3도\\n- **날씨**: 부분적으로 흐림\\n- **바람**: 산들 바람, 북서, 속도 4 m/s, 돌풍 11 m/s\\n- **습도**: 40%\\n- **기압**: 1004 hPa\\n- **자외선 지수**: 3.9 (보통)\\n- **가시성**: 100%\\n\\n### 부산\\n- **기온**: 아침 최저기온 17도, 낮 최고기온 26도\\n- **날씨**: 대체로 맑음\\n- **바람**: 온화한 날씨가 이어지고 있으며, 추위로 인한 불편함은 없음\\n\\n서울은 현재 매우 추운 날씨를 보이고 있으며, 부산은 비교적 온화한 날씨를 유지하고 있습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"stop\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-8e13cd89-11cc-4a79-8fa4-f9d381f44518\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [3.14s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [6.84s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"서울과 부산의 현재 날씨는 다음과 같습니다:\\n\\n### 서울\\n- **기온**: 영하 6.3도\\n- **날씨**: 부분적으로 흐림\\n- **바람**: 산들 바람, 북서, 속도 4 m/s, 돌풍 11 m/s\\n- **습도**: 40%\\n- **기압**: 1004 hPa\\n- **자외선 지수**: 3.9 (보통)\\n- **가시성**: 100%\\n\\n### 부산\\n- **기온**: 아침 최저기온 17도, 낮 최고기온 26도\\n- **날씨**: 대체로 맑음\\n- **바람**: 온화한 날씨가 이어지고 있으며, 추위로 인한 불편함은 없음\\n\\n서울은 현재 매우 추운 날씨를 보이고 있으며, 부산은 비교적 온화한 날씨를 유지하고 있습니다.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"서울과 부산의 날씨를 알려줘\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTGF_nWgnfaZ",
        "outputId": "484ba304-81a3-4069-9ba5-9e14d79fa9fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "서울과 부산의 현재 날씨는 다음과 같습니다:\n",
            "\n",
            "### 서울\n",
            "- **기온**: 영하 6.3도\n",
            "- **날씨**: 부분적으로 흐림\n",
            "- **바람**: 산들 바람, 북서, 속도 4 m/s, 돌풍 11 m/s\n",
            "- **습도**: 40%\n",
            "- **기압**: 1004 hPa\n",
            "- **자외선 지수**: 3.9 (보통)\n",
            "- **가시성**: 100%\n",
            "\n",
            "### 부산\n",
            "- **기온**: 아침 최저기온 17도, 낮 최고기온 26도\n",
            "- **날씨**: 대체로 맑음\n",
            "- **바람**: 온화한 날씨가 이어지고 있으며, 추위로 인한 불편함은 없음\n",
            "\n",
            "서울은 현재 매우 추운 날씨를 보이고 있으며, 부산은 비교적 온화한 날씨를 유지하고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI Tools Agent\n",
        "\n",
        "OpenAI API는 functions를 더 이상 사용하지 않고 tools를 사용합니다. tools API를 사용하면 모델에서 여러 함수를 한 번에 호출하도록 요청할 수 있으므로 일부 아키텍처에서 응답 시간을 줄일 수 있습니다. OpenAI 모델에는 tools agent를 사용하는 것이 좋습니다."
      ],
      "metadata": {
        "id": "mk4rfrr-EkU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"서울과 부산의 날씨를 알려줘\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1thfrc_jD974",
        "outputId": "2481c0f8-25b0-46be-b782-eb9557ec1b2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [4ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [9ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [905ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"index\": 0,\n",
            "                  \"id\": \"call_iNeveLV04iZKx4TJjpz1C6S3\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"query\\\": \\\"Seoul weather\\\"}\",\n",
            "                    \"name\": \"duckduckgo_search\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                },\n",
            "                {\n",
            "                  \"index\": 1,\n",
            "                  \"id\": \"call_VIAegqQpXmx3PcQuCNmtJFLb\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"query\\\": \\\"Busan weather\\\"}\",\n",
            "                    \"name\": \"duckduckgo_search\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ]\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"tool_calls\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-7be2c4b4-561e-4a84-848e-95d6abcf4b34\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": {\n",
            "                  \"query\": \"Seoul weather\"\n",
            "                },\n",
            "                \"id\": \"call_iNeveLV04iZKx4TJjpz1C6S3\"\n",
            "              },\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": {\n",
            "                  \"query\": \"Busan weather\"\n",
            "                },\n",
            "                \"id\": \"call_VIAegqQpXmx3PcQuCNmtJFLb\"\n",
            "              }\n",
            "            ],\n",
            "            \"tool_call_chunks\": [\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": \"{\\\"query\\\": \\\"Seoul weather\\\"}\",\n",
            "                \"id\": \"call_iNeveLV04iZKx4TJjpz1C6S3\",\n",
            "                \"index\": 0\n",
            "              },\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": \"{\\\"query\\\": \\\"Busan weather\\\"}\",\n",
            "                \"id\": \"call_VIAegqQpXmx3PcQuCNmtJFLb\",\n",
            "                \"index\": 1\n",
            "              }\n",
            "            ],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [925ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': 'Seoul weather'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [1.05s] Exiting Tool run with output:\n",
            "\u001b[0m\"The best time to visit Seoul is in the spring (April) and in the fall (October). These spring and fall months fall within the city's tourism shoulder season. Travellers will still enjoy mild to warm temperatures while avoiding the oppressive heat and humidity of the summer months. Besides comfortable weather, visiting at this time of year ... Seoul. Seoul Weather Forecast. Providing a local hourly Seoul weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Seoul weather today. Live weather reports from Seoul weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. Everything you need to know about today's weather in Seoul City Hall, Seoul, South Korea. High/Low, Precipitation Chances, Sunrise/Sunset, and today's Temperature History. The minimum value of the daily temperature is expected at around +66°F, the maximum is expected at around +88°F. At night the minimum temperature will be +46°F and the maximum +66°F. Detailed Weather Forecast ⚡ in Seoul for 14 days - 🌡️ air temperature, RealFeel, wind, precipitation, atmospheric pressure in Seoul, Seoul for 2 weeks ... Seoul Capital (Republic of Korea), elevation 38 m Press to show information about this location. Forecast Forecast. Other conditions Other conditions. Map Map. Details Details. It looks like you're using an old browser. To access all of the content on Yr, we recommend that you update your browser. ... Weather forecast for the next 10 days ...\"\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': 'Busan weather'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [1.03s] Exiting Tool run with output:\n",
            "\u001b[0m\"South Korea. Busan. Busan Weather Forecast. Providing a local hourly Busan weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Busan weather today. Live weather reports from Busan weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. Today's and tonight's Busan, South Korea weather forecast, weather conditions and Doppler radar from The Weather Channel and Weather.com The minimum value of the daily temperature is expected at around +41°F, the maximum is expected at around +63°F. At night the minimum temperature will be +37°F and the maximum +61°F. Detailed ⚡ Weather Forecast in Busan for 10 days - 🌡️ Air Temperature, RealFeel, Wind, Precipitation, Atmospheric Pressure in Busan, Busan - World ... 부산 광역시 (Busan) ☀ Weather forecast for 10 days, information from meteorological stations, webcams, sunrise and sunset, wind and precipitation maps for this place ... Weather report from station Pusan, Distance: 10 km (17:00 2024/05/17) Weather for the next 24 hours . 19:00 20:00 21:00 22:00 23:00 00:00 ... Hourly Local Weather Forecast, weather conditions, precipitation, dew point, humidity, wind from Weather.com and The Weather Channel\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [10ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\\nAI: \\nTool: The best time to visit Seoul is in the spring (April) and in the fall (October). These spring and fall months fall within the city's tourism shoulder season. Travellers will still enjoy mild to warm temperatures while avoiding the oppressive heat and humidity of the summer months. Besides comfortable weather, visiting at this time of year ... Seoul. Seoul Weather Forecast. Providing a local hourly Seoul weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Seoul weather today. Live weather reports from Seoul weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. Everything you need to know about today's weather in Seoul City Hall, Seoul, South Korea. High/Low, Precipitation Chances, Sunrise/Sunset, and today's Temperature History. The minimum value of the daily temperature is expected at around +66°F, the maximum is expected at around +88°F. At night the minimum temperature will be +46°F and the maximum +66°F. Detailed Weather Forecast ⚡ in Seoul for 14 days - 🌡️ air temperature, RealFeel, wind, precipitation, atmospheric pressure in Seoul, Seoul for 2 weeks ... Seoul Capital (Republic of Korea), elevation 38 m Press to show information about this location. Forecast Forecast. Other conditions Other conditions. Map Map. Details Details. It looks like you're using an old browser. To access all of the content on Yr, we recommend that you update your browser. ... Weather forecast for the next 10 days ...\\nTool: South Korea. Busan. Busan Weather Forecast. Providing a local hourly Busan weather forecast of rain, sun, wind, humidity and temperature. The Long-range 12 day forecast also includes detail for Busan weather today. Live weather reports from Busan weather stations and weather warnings that include risk of thunder, high UV index and forecast gales. Today's and tonight's Busan, South Korea weather forecast, weather conditions and Doppler radar from The Weather Channel and Weather.com The minimum value of the daily temperature is expected at around +41°F, the maximum is expected at around +63°F. At night the minimum temperature will be +37°F and the maximum +61°F. Detailed ⚡ Weather Forecast in Busan for 10 days - 🌡️ Air Temperature, RealFeel, Wind, Precipitation, Atmospheric Pressure in Busan, Busan - World ... 부산 광역시 (Busan) ☀ Weather forecast for 10 days, information from meteorological stations, webcams, sunrise and sunset, wind and precipitation maps for this place ... Weather report from station Pusan, Distance: 10 km (17:00 2024/05/17) Weather for the next 24 hours . 19:00 20:00 21:00 22:00 23:00 00:00 ... Hourly Local Weather Forecast, weather conditions, precipitation, dew point, humidity, wind from Weather.com and The Weather Channel\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [2.99s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"서울과 부산의 현재 날씨 정보를 알려드릴게요.\\n\\n### 서울 (Seoul)\\n- **최저 기온**: 약 19°C (66°F)\\n- **최고 기온**: 약 31°C (88°F)\\n- **날씨**: 현재 서울의 날씨는 맑고, 바람이 약간 불고 있습니다. \\n\\n### 부산 (Busan)\\n- **최저 기온**: 약 5°C (41°F)\\n- **최고 기온**: 약 17°C (63°F)\\n- **날씨**: 현재 부산의 날씨는 맑고, 바람이 약간 불고 있습니다.\\n\\n더 자세한 정보가 필요하시면 말씀해 주세요!\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"서울과 부산의 현재 날씨 정보를 알려드릴게요.\\n\\n### 서울 (Seoul)\\n- **최저 기온**: 약 19°C (66°F)\\n- **최고 기온**: 약 31°C (88°F)\\n- **날씨**: 현재 서울의 날씨는 맑고, 바람이 약간 불고 있습니다. \\n\\n### 부산 (Busan)\\n- **최저 기온**: 약 5°C (41°F)\\n- **최고 기온**: 약 17°C (63°F)\\n- **날씨**: 현재 부산의 날씨는 맑고, 바람이 약간 불고 있습니다.\\n\\n더 자세한 정보가 필요하시면 말씀해 주세요!\",\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"stop\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-b7d3359e-875d-4fa7-8664-64bbc9d93732\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [3.01s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [6.04s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"서울과 부산의 현재 날씨 정보를 알려드릴게요.\\n\\n### 서울 (Seoul)\\n- **최저 기온**: 약 19°C (66°F)\\n- **최고 기온**: 약 31°C (88°F)\\n- **날씨**: 현재 서울의 날씨는 맑고, 바람이 약간 불고 있습니다. \\n\\n### 부산 (Busan)\\n- **최저 기온**: 약 5°C (41°F)\\n- **최고 기온**: 약 17°C (63°F)\\n- **날씨**: 현재 부산의 날씨는 맑고, 바람이 약간 불고 있습니다.\\n\\n더 자세한 정보가 필요하시면 말씀해 주세요!\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVSJAdo-E3pU",
        "outputId": "52cec2e4-83f2-472d-b8ae-ad7ebb3c6e8b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "서울과 부산의 현재 날씨 정보를 알려드릴게요.\n",
            "\n",
            "### 서울 (Seoul)\n",
            "- **최저 기온**: 약 19°C (66°F)\n",
            "- **최고 기온**: 약 31°C (88°F)\n",
            "- **날씨**: 현재 서울의 날씨는 맑고, 바람이 약간 불고 있습니다. \n",
            "\n",
            "### 부산 (Busan)\n",
            "- **최저 기온**: 약 5°C (41°F)\n",
            "- **최고 기온**: 약 17°C (63°F)\n",
            "- **날씨**: 현재 부산의 날씨는 맑고, 바람이 약간 불고 있습니다.\n",
            "\n",
            "더 자세한 정보가 필요하시면 말씀해 주세요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUk1I4cuY_ef"
      },
      "source": [
        "### (칼럼) Function calling을 활용한 OurputParser, Extraction, Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G0rOddweWbQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57a06db-e08e-4b9b-e169-b3ca5c9da71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: https://python.langchain.com/docs/modules/model_io/chat/structured_output/Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.https://python.langchain.com/docs/use_cases/extraction/.If you notice other issues, please provide feedback here:https://github.com/langchain-ai/langchain/discussions/18154\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\\n\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: Extract and save the relevant entities mentioned in the following passage together with their properties.\\n\\nOnly extract the properties mentioned in the 'information_extraction' function.\\n\\nIf a property is not present and is not required in the function parameters, do not include it in the output.\\n\\nPassage:\\n\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] [1.26s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"arguments\": \"{\\\"info\\\":[{\\\"person_name\\\":\\\"Alex\\\",\\\"person_height\\\":5,\\\"person_hair_color\\\":\\\"blonde\\\"},{\\\"person_name\\\":\\\"Claudia\\\",\\\"person_height\\\":6,\\\"person_hair_color\\\":\\\"brunette\\\",\\\"dog_name\\\":\\\"Frosty\\\",\\\"dog_breed\\\":\\\"labrador\\\"}]}\",\n",
            "                \"name\": \"information_extraction\"\n",
            "              }\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 57,\n",
            "                \"prompt_tokens\": 213,\n",
            "                \"total_tokens\": 270\n",
            "              },\n",
            "              \"model_name\": \"gpt-3.5-turbo\",\n",
            "              \"system_fingerprint\": null,\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-328307ee-c12b-42f2-b8ad-665d6ce7c4a2-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 57,\n",
            "      \"prompt_tokens\": 213,\n",
            "      \"total_tokens\": 270\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LLMChain] [1.26s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": [\n",
            "    {\n",
            "      \"person_name\": \"Alex\",\n",
            "      \"person_height\": 5,\n",
            "      \"person_hair_color\": \"blonde\"\n",
            "    },\n",
            "    {\n",
            "      \"person_name\": \"Claudia\",\n",
            "      \"person_height\": 6,\n",
            "      \"person_hair_color\": \"brunette\",\n",
            "      \"dog_name\": \"Frosty\",\n",
            "      \"dog_breed\": \"labrador\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import create_extraction_chain\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_height\"],\n",
        "}\n",
        "text = \"\"\"\n",
        "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
        "\"\"\"\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "chain = create_extraction_chain(schema, chat)\n",
        "\n",
        "people = chain.invoke(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(people, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUGHhVcpnR0W",
        "outputId": "6b157fe1-9d7d-4cab-bf79-5f3c2c0d729d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"input\": \"\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\\n\",\n",
            "  \"text\": [\n",
            "    {\n",
            "      \"person_name\": \"Alex\",\n",
            "      \"person_height\": 5,\n",
            "      \"person_hair_color\": \"blonde\"\n",
            "    },\n",
            "    {\n",
            "      \"person_name\": \"Claudia\",\n",
            "      \"person_height\": 6,\n",
            "      \"person_hair_color\": \"brunette\",\n",
            "      \"dog_name\": \"Frosty\",\n",
            "      \"dog_breed\": \"labrador\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoyUU671fJ-N"
      },
      "source": [
        "## 요약"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcGAKOdafMy0"
      },
      "source": [
        "### (칼럼) Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KZedGP8fZPtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84e565b-b94e-4d73-d8bb-69f349ffe730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:QAEvalChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"query\": \"나는 시장에 가서 사과 10개를 샀어. 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 나는 몇 개의 사과를 가지고 있었니?\",\n",
            "  \"answer\": \"10개\",\n",
            "  \"result\": \"먼저 사과 10개로 시작했어.\\n이웃에게 2개, 수리공에게 2개를 나누어 주었으므로 사과가 6개가 남았어.\\n그런 다음 사과 5개를 더 사서 이제 사과가 11개가 되었어.\\n마지막으로 사과 1개를 먹었으므로 사과 10개가 남게 돼.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:QAEvalChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: You are a teacher grading a quiz.\\nYou are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student's answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: 나는 시장에 가서 사과 10개를 샀어. 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 나는 몇 개의 사과를 가지고 있었니?\\nSTUDENT ANSWER: 먼저 사과 10개로 시작했어.\\n이웃에게 2개, 수리공에게 2개를 나누어 주었으므로 사과가 6개가 남았어.\\n그런 다음 사과 5개를 더 사서 이제 사과가 11개가 되었어.\\n마지막으로 사과 1개를 먹었으므로 사과 10개가 남게 돼.\\nTRUE ANSWER: 10개\\nGRADE:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:QAEvalChain > llm:ChatOpenAI] [581ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"CORRECT\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"CORRECT\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 2,\n",
            "                \"prompt_tokens\": 369,\n",
            "                \"total_tokens\": 371\n",
            "              },\n",
            "              \"model_name\": \"gpt-4\",\n",
            "              \"system_fingerprint\": null,\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-6b2b49cd-de50-400c-aa22-bb3896b1b746-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 2,\n",
            "      \"prompt_tokens\": 369,\n",
            "      \"total_tokens\": 371\n",
            "    },\n",
            "    \"model_name\": \"gpt-4\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:QAEvalChain] [583ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"results\": \"CORRECT\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.evaluation import load_evaluator\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "evaluator = load_evaluator(\"qa\", eval_llm=chat)\n",
        "\n",
        "result = evaluator.evaluate_strings(\n",
        "    input=\"나는 시장에 가서 사과 10개를 샀어. 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 나는 몇 개의 사과를 가지고 있었니?\",\n",
        "    prediction=\"\"\"먼저 사과 10개로 시작했어.\n",
        "이웃에게 2개, 수리공에게 2개를 나누어 주었으므로 사과가 6개가 남았어.\n",
        "그런 다음 사과 5개를 더 사서 이제 사과가 11개가 되었어.\n",
        "마지막으로 사과 1개를 먹었으므로 사과 10개가 남게 돼.\"\"\",\n",
        "    reference=\"10개\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgJgyn5LnZ_y",
        "outputId": "5c309f44-7647-42cb-d833-c8604403985a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': 'CORRECT', 'value': 'CORRECT', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01zbQY3op1Gc"
      },
      "source": [
        "위 입력은 [Chain-of-Thought Prompting | Prompt Engineering Guide](https://www.promptingguide.ai/kr/techniques/cot)에서 인용했습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}