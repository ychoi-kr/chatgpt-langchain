{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychoi-kr/langchain-book/blob/main/chapter5/5_2_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 보안 비밀에 OpenAI API 키를 등록한 경우\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "M13h9QsoqGhY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WqgjYwQUemjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6007982-6dbe-4b27-e6b4-3f342428fbaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.1.19 in /usr/local/lib/python3.10/dist-packages (0.1.19)\n",
            "Requirement already satisfied: openai==1.16.2 in /usr/local/lib/python3.10/dist-packages (1.16.2)\n",
            "Requirement already satisfied: langchain-openai==0.1.1 in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: langchain-experimental==0.0.56 in /usr/local/lib/python3.10/dist-packages (0.0.56)\n",
            "Requirement already satisfied: langchainhub==0.1.15 in /usr/local/lib/python3.10/dist-packages (0.1.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.16.2) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.16.2) (4.11.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.1) (0.7.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub==0.1.15) (2.31.0.20240406)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.16.2) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.16.2) (1.2.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.16.2) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.16.2) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.16.2) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.1) (2023.12.25)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.19 openai==1.16.2 langchain-openai==0.1.1 langchain-experimental==0.0.56 langchainhub==0.1.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4Fz0OFVZmSq"
      },
      "source": [
        "## 5-2 Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HSybywiZn6c"
      },
      "source": [
        "### Agents 사용 예"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_1RES8TRp1GX"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "\n",
        "langchain.verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qlRHx6ejZBbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc8eb5f-e5b8-4bc3-db96-9b053d2ae6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI can use the terminal to list the files in the sample_data directory.\n",
            "Action: terminal\n",
            "Action Input: ls sample_data\u001b[0mExecuting command:\n",
            " ls sample_data\n",
            "\u001b[36;1m\u001b[1;3manscombe.json\n",
            "california_housing_test.csv\n",
            "california_housing_train.csv\n",
            "mnist_test.csv\n",
            "mnist_train_small.csv\n",
            "README.md\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], allow_dangerous_tools=True)\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"output\"])"
      ],
      "metadata": {
        "id": "kTodBr7Wiw8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb17c15-d40d-40d0-bfbc-779843ca783d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json, california_housing_test.csv, california_housing_train.csv, mnist_test.csv, mnist_train_small.csv, README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U2AKd4BsSEt"
      },
      "source": [
        "### Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pvJUF7XogVRI"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "def my_super_func(param):\n",
        "    return \"42\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=my_super_func,\n",
        "        name=\"The_Answer\",\n",
        "        description=\"생명, 우주, 그리고 모든 것에 대한 궁극적인 질문의 답\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MoEjpv2XtemN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2b272ae-7b3e-4e88-e492-1280101d9510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should seek the ultimate answer to the truth of this world\n",
            "Action: The_Answer\n",
            "Action Input: 이 세계의 진리\u001b[0m\u001b[36;1m\u001b[1;3m42\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 42\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '이 세계의 진리를 알려주세요', 'output': '42'}\n"
          ]
        }
      ],
      "source": [
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "result = agent_executor.invoke({\"input\": \"이 세계의 진리를 알려주세요\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MFW6L4Dbtkpv",
        "outputId": "da3a337c-5d4b-48e5-e47d-059cee7177ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "summarize_template = \"\"\"아래의 글을 결론만 한 마디로 요약해 주세요.\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=summarize_chain.run,\n",
        "        name=\"Summarizer\",\n",
        "        description=\"Text summarizer\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kAjRYZTLv7nC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58352df9-14e9-4866-b953-dc4aeeed9ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the Summarizer tool to summarize the text provided in Korean.\n",
            "Action: Summarizer\n",
            "Action Input: 안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m아래의 글을 결론만 한 마디로 요약해 주세요.\n",
            "\n",
            "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다. 제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다. 질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mChatGPT는 OpenAI가 개발한 AI 언어 모델로, 다양한 주제에 대한 질문에 답하거나 대화를 나누는 것을 전문으로 합니다.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: ChatGPT는 OpenAI가 개발한 AI 언어 모델로, 다양한 주제에 대한 질문에 답하거나 대화를 나누는 것을 전문으로 합니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': '다음을 요약해 주세요.\\n\\n안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\\n제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\\n질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.', 'output': 'ChatGPT는 OpenAI가 개발한 AI 언어 모델로, 다양한 주제에 대한 질문에 답하거나 대화를 나누는 것을 전문으로 합니다.'}\n"
          ]
        }
      ],
      "source": [
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "text = \"\"\"다음을 요약해 주세요.\n",
        "\n",
        "안녕하세요! 저는 ChatGPT라고 불리는 AI 언어 모델입니다. OpenAI가 개발한 GPT-3.5 아키텍처를 기반으로 합니다. 저는 자연어 이해와 생성을 전문으로 하며, 다양한 주제에 대한 질문에 답하거나, 대화를 나누는 것을 잘합니다.\n",
        "제 트레이닝 데이터는 2021년 9월까지의 정보를 기반으로 하기 때문에, 그 이후의 사건에 대해서는 지식이 없습니다. 하지만, 가능한 한 도움을 드리기 위해 노력할 것입니다.\n",
        "질문이나 대화, 정보 공유 등, 어떤 도움이든 편하게 말씀해 주세요! 잘 부탁드립니다.\"\"\"\n",
        "\n",
        "result = agent_executor.invoke({\"input\": text})\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bTNTRGNZNM"
      },
      "source": [
        "### Function calling을 사용하는 OpenAI Functions Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XP8Nm_1d6zZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792e34fb-41a9-4438-bfd3-9454f1598f22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `terminal` with `{'commands': 'ls sample_data'}`\n",
            "\n",
            "\n",
            "\u001b[0mExecuting command:\n",
            " ['ls sample_data']\n",
            "\u001b[36;1m\u001b[1;3manscombe.json\n",
            "california_housing_test.csv\n",
            "california_housing_train.csv\n",
            "mnist_test.csv\n",
            "mnist_train_small.csv\n",
            "README.md\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/tools/shell/tool.py:32: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m`sample_data` 디렉터리에 있는 파일 목록은 다음과 같습니다:\n",
            "1. anscombe.json\n",
            "2. california_housing_test.csv\n",
            "3. california_housing_train.csv\n",
            "4. mnist_test.csv\n",
            "5. mnist_train_small.csv\n",
            "6. README.md\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'sample_data 디렉터리에 있는 파일 목록을 알려줘',\n",
              " 'output': '`sample_data` 디렉터리에 있는 파일 목록은 다음과 같습니다:\\n1. anscombe.json\\n2. california_housing_test.csv\\n3. california_housing_train.csv\\n4. mnist_test.csv\\n5. mnist_train_small.csv\\n6. README.md'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], allow_dangerous_tools=True)\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "\n",
        "agent_executor.invoke({\"input\": \"sample_data 디렉터리에 있는 파일 목록을 알려줘\"})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV6Mx0TUO_hT"
      },
      "source": [
        "### 여러 도구를 한 번에 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bJTSM5gIPDOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7479f4e4-0eb4-4438-f6e7-d449924f503e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: duckduckgo_search==5.3.0b4 in /usr/local/lib/python3.10/dist-packages (5.3.0b4)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search==5.3.0b4) (8.1.7)\n",
            "Requirement already satisfied: httpx[brotli,http2,socks]>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from duckduckgo_search==5.3.0b4) (0.27.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (1.3.1)\n",
            "Requirement already satisfied: socksio==1.* in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (1.0.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (4.1.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (1.1.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (0.14.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (4.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[brotli,http2,socks]>=0.27.0->duckduckgo_search==5.3.0b4) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install duckduckgo_search==5.3.0b4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uJAM26YzQQOa"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "\n",
        "langchain.debug = True\n",
        "langchain.verbose = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EgUyIpfrNq1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6570faa6-e1a2-4d00-e71d-8dfe891a98f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [11ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [2ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [1.10s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"function_call\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"arguments\": \"{\\\"query\\\":\\\"서울 날씨\\\"}\",\n",
            "                \"name\": \"duckduckgo_search\"\n",
            "              }\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"function_call\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-b8c923ed-23d0-4ed2-9c7e-35054649842a\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [1.12s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': '서울 날씨'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [1.35s] Exiting Tool run with output:\n",
            "\u001b[0m\"Monday 20 May. 28° / 14°. 0 mm. 3 m/s. Open hourly forecast. Updated 17:26. How often is the weather forecast updated? Forecast as PDF Forecast as SVG. Weather forecast for Seoul for the next 10 days. 맑은 날씨 속에 기온도 크게 오를 것으로 보이는데요. 우선 아침에는 서울 기온이 12도, 대구 11도로 오늘보다 높아지며 쌀쌀함이 덜하겠고, 오늘 (16일) 아침 날씨가 많이 쌀쌀합니다. 서울의 아침 기온이 현재 7도 정도로, 하루 만에 뚝 떨어졌습니다. 오늘 전국적으로 강한 바람도 예보돼 ... 내일 아침 서울 기온이 5월 기준으로는 14년 만에 가장 낮은 영상 8도까지 떨어집니다. ... [날씨] 돌풍·호우 주의…내일 아침 기온 14년 만 최저 ... 서울 광화문에 나가 있는 기상캐스터 연결해 자세한 날씨 알아보겠습니다. 금채림 캐스터 전해주세요. 기상캐스터 지금 서울은 비가 그치고 맑은 하늘이 드러나 있습니다. 쌀쌀함만 감돌고 있는데요. 서쪽 지역은 비가 잦아들었고요.\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [24ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [36ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\\nAI: {'arguments': '{\\\"query\\\":\\\"서울 날씨\\\"}', 'name': 'duckduckgo_search'}\\nFunction: Monday 20 May. 28° / 14°. 0 mm. 3 m/s. Open hourly forecast. Updated 17:26. How often is the weather forecast updated? Forecast as PDF Forecast as SVG. Weather forecast for Seoul for the next 10 days. 맑은 날씨 속에 기온도 크게 오를 것으로 보이는데요. 우선 아침에는 서울 기온이 12도, 대구 11도로 오늘보다 높아지며 쌀쌀함이 덜하겠고, 오늘 (16일) 아침 날씨가 많이 쌀쌀합니다. 서울의 아침 기온이 현재 7도 정도로, 하루 만에 뚝 떨어졌습니다. 오늘 전국적으로 강한 바람도 예보돼 ... 내일 아침 서울 기온이 5월 기준으로는 14년 만에 가장 낮은 영상 8도까지 떨어집니다. ... [날씨] 돌풍·호우 주의…내일 아침 기온 14년 만 최저 ... 서울 광화문에 나가 있는 기상캐스터 연결해 자세한 날씨 알아보겠습니다. 금채림 캐스터 전해주세요. 기상캐스터 지금 서울은 비가 그치고 맑은 하늘이 드러나 있습니다. 쌀쌀함만 감돌고 있는데요. 서쪽 지역은 비가 잦아들었고요.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [1.08s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"function_call\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"arguments\": \"{\\\"query\\\":\\\"부산 날씨\\\"}\",\n",
            "                \"name\": \"duckduckgo_search\"\n",
            "              }\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"function_call\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-ad002614-bf58-4fc6-a883-eeb4a3630013\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [2ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [1.15s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': '부산 날씨'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [927ms] Exiting Tool run with output:\n",
            "\u001b[0m\"부산cc 날씨 컨트리클럽 주간일기예보를 알아보겠습니다. 현재 컨트리클럽 주변의 날씨 상황과 함께 실시간으로 반영되는 날씨 정보를 확인할 수 있으며, 주간 일별날씨예보와 비, 바람, 돌풍, 풍향, 눈 등의 세부적인 기상변화를 확인할 수 있습니다. 부산 광역시 (Busan) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 Ventusky: 지도상 일기예보 소개 부분적으로 흐린 날씨 바람: 산들 바람 , 북서 , 속도 2 초당 미터 돌풍: 6 초당 미터 상대 습도: 35% 흐림: 18% 기압: 980 고전력 증폭기 자외선 지수: 0,4 (낮음) 가시성: 100% 14일 부산지역은 대체로 맑은 날씨가 될 것으로 부산기상청은 예보했다. 이날 낮 최고기온은 24도, 15일 아침 최저기온은 15도로 예상됐다. [날씨] 부산 오늘 저녁까지 곳곳 비…내일 무더위·소나기 ... 뉴스7(부산) 부산은 현재 하늘에 구름만 지나고 있습니다. 비구름이 국지적으로 발달하면서 지역별로 편차가 큰데요. 저녁까지 최대 40mm 안팎의 비가 뿌리다 완전히 물러가겠습니다.\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [9ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [14ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [19ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\\nAI: {'arguments': '{\\\"query\\\":\\\"서울 날씨\\\"}', 'name': 'duckduckgo_search'}\\nFunction: Monday 20 May. 28° / 14°. 0 mm. 3 m/s. Open hourly forecast. Updated 17:26. How often is the weather forecast updated? Forecast as PDF Forecast as SVG. Weather forecast for Seoul for the next 10 days. 맑은 날씨 속에 기온도 크게 오를 것으로 보이는데요. 우선 아침에는 서울 기온이 12도, 대구 11도로 오늘보다 높아지며 쌀쌀함이 덜하겠고, 오늘 (16일) 아침 날씨가 많이 쌀쌀합니다. 서울의 아침 기온이 현재 7도 정도로, 하루 만에 뚝 떨어졌습니다. 오늘 전국적으로 강한 바람도 예보돼 ... 내일 아침 서울 기온이 5월 기준으로는 14년 만에 가장 낮은 영상 8도까지 떨어집니다. ... [날씨] 돌풍·호우 주의…내일 아침 기온 14년 만 최저 ... 서울 광화문에 나가 있는 기상캐스터 연결해 자세한 날씨 알아보겠습니다. 금채림 캐스터 전해주세요. 기상캐스터 지금 서울은 비가 그치고 맑은 하늘이 드러나 있습니다. 쌀쌀함만 감돌고 있는데요. 서쪽 지역은 비가 잦아들었고요.\\nAI: {'arguments': '{\\\"query\\\":\\\"부산 날씨\\\"}', 'name': 'duckduckgo_search'}\\nFunction: 부산cc 날씨 컨트리클럽 주간일기예보를 알아보겠습니다. 현재 컨트리클럽 주변의 날씨 상황과 함께 실시간으로 반영되는 날씨 정보를 확인할 수 있으며, 주간 일별날씨예보와 비, 바람, 돌풍, 풍향, 눈 등의 세부적인 기상변화를 확인할 수 있습니다. 부산 광역시 (Busan) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 Ventusky: 지도상 일기예보 소개 부분적으로 흐린 날씨 바람: 산들 바람 , 북서 , 속도 2 초당 미터 돌풍: 6 초당 미터 상대 습도: 35% 흐림: 18% 기압: 980 고전력 증폭기 자외선 지수: 0,4 (낮음) 가시성: 100% 14일 부산지역은 대체로 맑은 날씨가 될 것으로 부산기상청은 예보했다. 이날 낮 최고기온은 24도, 15일 아침 최저기온은 15도로 예상됐다. [날씨] 부산 오늘 저녁까지 곳곳 비…내일 무더위·소나기 ... 뉴스7(부산) 부산은 현재 하늘에 구름만 지나고 있습니다. 비구름이 국지적으로 발달하면서 지역별로 편차가 큰데요. 저녁까지 최대 40mm 안팎의 비가 뿌리다 완전히 물러가겠습니다.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [5.88s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"서울의 날씨는 맑고 기온은 28도에서 14도 사이이며, 바람 속도는 3m/s입니다. 내일 아침 서울의 기온은 8도까지 떨어질 예정이고, 강한 바람이 예보되고 있습니다.\\n\\n부산의 날씨는 대체로 맑고, 바람은 산들 바람으로 북서쪽에서 불며 속도는 2m/s입니다. 오늘 낮 최고기온은 24도, 내일 아침 최저기온은 15도로 예상되고 있습니다. 현재 부산은 구름이 지나가고 있으며, 저녁까지 비가 뿌리다가 완전히 물러갈 것으로 예보되고 있습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"서울의 날씨는 맑고 기온은 28도에서 14도 사이이며, 바람 속도는 3m/s입니다. 내일 아침 서울의 기온은 8도까지 떨어질 예정이고, 강한 바람이 예보되고 있습니다.\\n\\n부산의 날씨는 대체로 맑고, 바람은 산들 바람으로 북서쪽에서 불며 속도는 2m/s입니다. 오늘 낮 최고기온은 24도, 내일 아침 최저기온은 15도로 예상되고 있습니다. 현재 부산은 구름이 지나가고 있으며, 저녁까지 비가 뿌리다가 완전히 물러갈 것으로 예보되고 있습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"stop\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-0d103aa4-41c9-435b-8e69-f867f550859b\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [5.92s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [10.55s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"서울의 날씨는 맑고 기온은 28도에서 14도 사이이며, 바람 속도는 3m/s입니다. 내일 아침 서울의 기온은 8도까지 떨어질 예정이고, 강한 바람이 예보되고 있습니다.\\n\\n부산의 날씨는 대체로 맑고, 바람은 산들 바람으로 북서쪽에서 불며 속도는 2m/s입니다. 오늘 낮 최고기온은 24도, 내일 아침 최저기온은 15도로 예상되고 있습니다. 현재 부산은 구름이 지나가고 있으며, 저녁까지 비가 뿌리다가 완전히 물러갈 것으로 예보되고 있습니다.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"서울과 부산의 날씨를 알려줘\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTGF_nWgnfaZ",
        "outputId": "5baaaf4c-4182-480e-bedb-1fef52fbc9a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "서울의 날씨는 맑고 기온은 28도에서 14도 사이이며, 바람 속도는 3m/s입니다. 내일 아침 서울의 기온은 8도까지 떨어질 예정이고, 강한 바람이 예보되고 있습니다.\n",
            "\n",
            "부산의 날씨는 대체로 맑고, 바람은 산들 바람으로 북서쪽에서 불며 속도는 2m/s입니다. 오늘 낮 최고기온은 24도, 내일 아침 최저기온은 15도로 예상되고 있습니다. 현재 부산은 구름이 지나가고 있으며, 저녁까지 비가 뿌리다가 완전히 물러갈 것으로 예보되고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI Tools Agent\n",
        "\n",
        "OpenAI API는 functions를 더 이상 사용하지 않고 tools를 사용합니다. tools API를 사용하면 모델에서 여러 함수를 한 번에 호출하도록 요청할 수 있으므로 일부 아키텍처에서 응답 시간을 줄일 수 있습니다. OpenAI 모델에는 tools agent를 사용하는 것이 좋습니다."
      ],
      "metadata": {
        "id": "mk4rfrr-EkU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"서울과 부산의 날씨를 알려줘\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1thfrc_jD974",
        "outputId": "1fe16466-f1b4-42df-fcfc-4abaa6924d11"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [11ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"서울과 부산의 날씨를 알려줘\",\n",
            "  \"intermediate_steps\": [],\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [1.95s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"index\": 0,\n",
            "                  \"id\": \"call_M4HIOOE4L0kBM8AJRaTB9xpD\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"query\\\": \\\"날씨 서울\\\"}\",\n",
            "                    \"name\": \"duckduckgo_search\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                },\n",
            "                {\n",
            "                  \"index\": 1,\n",
            "                  \"id\": \"call_btqCzK6RjFqoE2k3TDq0Pr3v\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\\"query\\\": \\\"날씨 부산\\\"}\",\n",
            "                    \"name\": \"duckduckgo_search\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ]\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"tool_calls\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-5efa8ec9-a5b4-46f8-9351-af089662a889\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": {\n",
            "                  \"query\": \"날씨 서울\"\n",
            "                },\n",
            "                \"id\": \"call_M4HIOOE4L0kBM8AJRaTB9xpD\"\n",
            "              },\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": {\n",
            "                  \"query\": \"날씨 부산\"\n",
            "                },\n",
            "                \"id\": \"call_btqCzK6RjFqoE2k3TDq0Pr3v\"\n",
            "              }\n",
            "            ],\n",
            "            \"tool_call_chunks\": [\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": \"{\\\"query\\\": \\\"날씨 서울\\\"}\",\n",
            "                \"id\": \"call_M4HIOOE4L0kBM8AJRaTB9xpD\",\n",
            "                \"index\": 0\n",
            "              },\n",
            "              {\n",
            "                \"name\": \"duckduckgo_search\",\n",
            "                \"args\": \"{\\\"query\\\": \\\"날씨 부산\\\"}\",\n",
            "                \"id\": \"call_btqCzK6RjFqoE2k3TDq0Pr3v\",\n",
            "                \"index\": 1\n",
            "              }\n",
            "            ],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [1.98s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': '날씨 서울'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [937ms] Exiting Tool run with output:\n",
            "\u001b[0m\"Monday 20 May. 28° / 14°. 0 mm. 3 m/s. Open hourly forecast. Updated 17:26. How often is the weather forecast updated? Forecast as PDF Forecast as SVG. Weather forecast for Seoul for the next 10 days. 맑은 날씨 속에 기온도 크게 오를 것으로 보이는데요. 우선 아침에는 서울 기온이 12도, 대구 11도로 오늘보다 높아지며 쌀쌀함이 덜하겠고, 오늘 (16일) 아침 날씨가 많이 쌀쌀합니다. 서울의 아침 기온이 현재 7도 정도로, 하루 만에 뚝 떨어졌습니다. 오늘 전국적으로 강한 바람도 예보돼 ... ㈜와이티엔 서울특별시 마포구 상암산로 76 (상암동) 대표자: 김백 대표전화: 02-398-8000 팩스: 02-398-8129 사업자등록번호: 102-81-32883 자세한 날씨 알아보겠습... 메뉴 바로가기 ... 오늘 서울 낮 기온은 20도, 광주는 21도로 예상됩니다. 내일 낮부터는 다시 예년 기온을 웃돌겠고요,\"\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': '날씨 부산'}\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:duckduckgo_search] [993ms] Exiting Tool run with output:\n",
            "\u001b[0m\"부산cc 날씨 컨트리클럽 주간일기예보를 알아보겠습니다. 현재 컨트리클럽 주변의 날씨 상황과 함께 실시간으로 반영되는 날씨 정보를 확인할 수 있으며, 주간 일별날씨예보와 비, 바람, 돌풍, 풍향, 눈 등의 세부적인 기상변화를 확인할 수 있습니다. 부산 광역시 (Busan) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 Ventusky: 지도상 일기예보 소개 부분적으로 흐린 날씨 바람: 산들 바람 , 북서 , 속도 2 초당 미터 돌풍: 6 초당 미터 상대 습도: 35% 흐림: 18% 기압: 980 고전력 증폭기 자외선 지수: 0,4 (낮음) 가시성: 100% 부산과 울산, 경남에선 모레까지 50에서 최대 120mm의 비가 내리겠습니다. 특히 모레 새벽부터 밤사이, 집중호우가 예상되고요. 장기간 이어지던 폭염특보도 모두 해제됐습니다. 낮 최고 기온 30도 안팎에 그치며, 오늘보다 약간 낮겠습니다. 바다의 물결은 ... (부산=뉴스1) 손연우 기자 | 부산과 경남은 8일 대체로 흐리다가 밤부터 맑아진다. 부산과 경남내륙은 오전 6시까지, 경남남해안은 오전 6~9시 가끔 비가 오는 곳이 있다. ... [오늘의 날씨] 부산·경남(8일, 수)오전까지 비 최대 20㎜, 강풍 유의 (부산=뉴스1) 손연우 ...\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [3ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [7ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [12ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [2ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant\\nHuman: 서울과 부산의 날씨를 알려줘\\nAI: \\nTool: Monday 20 May. 28° / 14°. 0 mm. 3 m/s. Open hourly forecast. Updated 17:26. How often is the weather forecast updated? Forecast as PDF Forecast as SVG. Weather forecast for Seoul for the next 10 days. 맑은 날씨 속에 기온도 크게 오를 것으로 보이는데요. 우선 아침에는 서울 기온이 12도, 대구 11도로 오늘보다 높아지며 쌀쌀함이 덜하겠고, 오늘 (16일) 아침 날씨가 많이 쌀쌀합니다. 서울의 아침 기온이 현재 7도 정도로, 하루 만에 뚝 떨어졌습니다. 오늘 전국적으로 강한 바람도 예보돼 ... ㈜와이티엔 서울특별시 마포구 상암산로 76 (상암동) 대표자: 김백 대표전화: 02-398-8000 팩스: 02-398-8129 사업자등록번호: 102-81-32883 자세한 날씨 알아보겠습... 메뉴 바로가기 ... 오늘 서울 낮 기온은 20도, 광주는 21도로 예상됩니다. 내일 낮부터는 다시 예년 기온을 웃돌겠고요,\\nTool: 부산cc 날씨 컨트리클럽 주간일기예보를 알아보겠습니다. 현재 컨트리클럽 주변의 날씨 상황과 함께 실시간으로 반영되는 날씨 정보를 확인할 수 있으며, 주간 일별날씨예보와 비, 바람, 돌풍, 풍향, 눈 등의 세부적인 기상변화를 확인할 수 있습니다. 부산 광역시 (Busan) ☀ 10일 기간 일기예보, 기상 정보, 웹카메라 화면, 일출 및 일몰, 지역의 풍속 및 강수량 Ventusky: 지도상 일기예보 소개 부분적으로 흐린 날씨 바람: 산들 바람 , 북서 , 속도 2 초당 미터 돌풍: 6 초당 미터 상대 습도: 35% 흐림: 18% 기압: 980 고전력 증폭기 자외선 지수: 0,4 (낮음) 가시성: 100% 부산과 울산, 경남에선 모레까지 50에서 최대 120mm의 비가 내리겠습니다. 특히 모레 새벽부터 밤사이, 집중호우가 예상되고요. 장기간 이어지던 폭염특보도 모두 해제됐습니다. 낮 최고 기온 30도 안팎에 그치며, 오늘보다 약간 낮겠습니다. 바다의 물결은 ... (부산=뉴스1) 손연우 기자 | 부산과 경남은 8일 대체로 흐리다가 밤부터 맑아진다. 부산과 경남내륙은 오전 6시까지, 경남남해안은 오전 6~9시 가끔 비가 오는 곳이 있다. ... [오늘의 날씨] 부산·경남(8일, 수)오전까지 비 최대 20㎜, 강풍 유의 (부산=뉴스1) 손연우 ...\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [1.97s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"서울의 날씨는 오늘 28도에서 14도로 맑고 바람이 3m/s로 불고 있습니다. 부산의 날씨는 오늘 20도에서 8도로 흐리고 바람이 2m/s로 불고 있습니다.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"서울의 날씨는 오늘 28도에서 14도로 맑고 바람이 3m/s로 불고 있습니다. 부산의 날씨는 오늘 20도에서 8도로 흐리고 바람이 2m/s로 불고 있습니다.\",\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"stop\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-dea10703-bae8-456f-b4ca-5a10a5b5fea2\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIToolsAgentOutputParser] [6ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [2.01s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [5.94s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"서울의 날씨는 오늘 28도에서 14도로 맑고 바람이 3m/s로 불고 있습니다. 부산의 날씨는 오늘 20도에서 8도로 흐리고 바람이 2m/s로 불고 있습니다.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVSJAdo-E3pU",
        "outputId": "82a2e30b-b02e-40d6-a829-cde9f777ee74"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "서울의 날씨는 오늘 28도에서 14도로 맑고 바람이 3m/s로 불고 있습니다. 부산의 날씨는 오늘 20도에서 8도로 흐리고 바람이 2m/s로 불고 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUk1I4cuY_ef"
      },
      "source": [
        "### (칼럼) Function calling을 활용한 OurputParser, Extraction, Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "G0rOddweWbQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec4c6f96-e02e-4841-cd3f-c1e53d5f01be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: https://python.langchain.com/docs/modules/model_io/chat/structured_output/Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.https://python.langchain.com/docs/use_cases/extraction/.If you notice other issues, please provide feedback here:https://github.com/langchain-ai/langchain/discussions/18154\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\\n\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: Extract and save the relevant entities mentioned in the following passage together with their properties.\\n\\nOnly extract the properties mentioned in the 'information_extraction' function.\\n\\nIf a property is not present and is not required in the function parameters, do not include it in the output.\\n\\nPassage:\\n\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LLMChain > llm:ChatOpenAI] [1.87s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"function_call\": {\n",
            "                \"arguments\": \"{\\\"info\\\":[{\\\"person_name\\\":\\\"Alex\\\",\\\"person_height\\\":5,\\\"person_hair_color\\\":\\\"blonde\\\"},{\\\"person_name\\\":\\\"Claudia\\\",\\\"person_height\\\":6,\\\"person_hair_color\\\":\\\"brunette\\\",\\\"dog_name\\\":\\\"Frosty\\\",\\\"dog_breed\\\":\\\"labrador\\\"}]}\",\n",
            "                \"name\": \"information_extraction\"\n",
            "              }\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 57,\n",
            "                \"prompt_tokens\": 213,\n",
            "                \"total_tokens\": 270\n",
            "              },\n",
            "              \"model_name\": \"gpt-3.5-turbo\",\n",
            "              \"system_fingerprint\": null,\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-e6135585-cb11-410b-8cbd-c68449d87983-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 57,\n",
            "      \"prompt_tokens\": 213,\n",
            "      \"total_tokens\": 270\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LLMChain] [1.88s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": [\n",
            "    {\n",
            "      \"person_name\": \"Alex\",\n",
            "      \"person_height\": 5,\n",
            "      \"person_hair_color\": \"blonde\"\n",
            "    },\n",
            "    {\n",
            "      \"person_name\": \"Claudia\",\n",
            "      \"person_height\": 6,\n",
            "      \"person_hair_color\": \"brunette\",\n",
            "      \"dog_name\": \"Frosty\",\n",
            "      \"dog_breed\": \"labrador\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import create_extraction_chain\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_height\"],\n",
        "}\n",
        "text = \"\"\"\n",
        "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
        "\"\"\"\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "chain = create_extraction_chain(schema, chat)\n",
        "\n",
        "people = chain.invoke(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(json.dumps(people, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUGHhVcpnR0W",
        "outputId": "7b025879-ab57-4405-f309-fabf451c99d5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"input\": \"\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\\n\",\n",
            "  \"text\": [\n",
            "    {\n",
            "      \"person_name\": \"Alex\",\n",
            "      \"person_height\": 5,\n",
            "      \"person_hair_color\": \"blonde\"\n",
            "    },\n",
            "    {\n",
            "      \"person_name\": \"Claudia\",\n",
            "      \"person_height\": 6,\n",
            "      \"person_hair_color\": \"brunette\",\n",
            "      \"dog_name\": \"Frosty\",\n",
            "      \"dog_breed\": \"labrador\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoyUU671fJ-N"
      },
      "source": [
        "## 요약"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcGAKOdafMy0"
      },
      "source": [
        "### (칼럼) Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KZedGP8fZPtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26730e37-b41f-40b4-b417-10096ec5530a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:QAEvalChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"query\": \"나는 시장에 가서 사과 10개를 샀어. 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 나는 몇 개의 사과를 가지고 있었니?\",\n",
            "  \"answer\": \"10개\",\n",
            "  \"result\": \"먼저 사과 10개로 시작했어.\\n이웃에게 2개, 수리공에게 2개를 나누어 주었으므로 사과가 6개가 남았어.\\n그런 다음 사과 5개를 더 사서 이제 사과가 11개가 되었어.\\n마지막으로 사과 1개를 먹었으므로 사과 10개가 남게 돼.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:QAEvalChain > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: You are a teacher grading a quiz.\\nYou are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\\n\\nExample Format:\\nQUESTION: question here\\nSTUDENT ANSWER: student's answer here\\nTRUE ANSWER: true answer here\\nGRADE: CORRECT or INCORRECT here\\n\\nGrade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin! \\n\\nQUESTION: 나는 시장에 가서 사과 10개를 샀어. 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 나는 몇 개의 사과를 가지고 있었니?\\nSTUDENT ANSWER: 먼저 사과 10개로 시작했어.\\n이웃에게 2개, 수리공에게 2개를 나누어 주었으므로 사과가 6개가 남았어.\\n그런 다음 사과 5개를 더 사서 이제 사과가 11개가 되었어.\\n마지막으로 사과 1개를 먹었으므로 사과 10개가 남게 돼.\\nTRUE ANSWER: 10개\\nGRADE:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:QAEvalChain > llm:ChatOpenAI] [857ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"CORRECT\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"CORRECT\",\n",
            "            \"response_metadata\": {\n",
            "              \"token_usage\": {\n",
            "                \"completion_tokens\": 2,\n",
            "                \"prompt_tokens\": 369,\n",
            "                \"total_tokens\": 371\n",
            "              },\n",
            "              \"model_name\": \"gpt-4\",\n",
            "              \"system_fingerprint\": null,\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"logprobs\": null\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run-86a6f775-c44d-49a1-b5d4-4fc37ecbea16-0\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 2,\n",
            "      \"prompt_tokens\": 369,\n",
            "      \"total_tokens\": 371\n",
            "    },\n",
            "    \"model_name\": \"gpt-4\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:QAEvalChain] [860ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"results\": \"CORRECT\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.evaluation import load_evaluator\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "evaluator = load_evaluator(\"qa\", eval_llm=chat)\n",
        "\n",
        "result = evaluator.evaluate_strings(\n",
        "    input=\"나는 시장에 가서 사과 10개를 샀어. 사과 2개를 이웃에게 주고, 2개를 수리공에게 주었어. 그리고 사과 5개를 더 사서 1개는 내가 먹었어. 나는 몇 개의 사과를 가지고 있었니?\",\n",
        "    prediction=\"\"\"먼저 사과 10개로 시작했어.\n",
        "이웃에게 2개, 수리공에게 2개를 나누어 주었으므로 사과가 6개가 남았어.\n",
        "그런 다음 사과 5개를 더 사서 이제 사과가 11개가 되었어.\n",
        "마지막으로 사과 1개를 먹었으므로 사과 10개가 남게 돼.\"\"\",\n",
        "    reference=\"10개\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgJgyn5LnZ_y",
        "outputId": "69dfa144-6790-44c1-ea9d-2eadcde4a366"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': 'CORRECT', 'value': 'CORRECT', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01zbQY3op1Gc"
      },
      "source": [
        "위 입력은 [Chain-of-Thought Prompting | Prompt Engineering Guide](https://www.promptingguide.ai/kr/techniques/cot)에서 인용했습니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}