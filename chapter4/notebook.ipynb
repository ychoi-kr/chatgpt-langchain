{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychoi-kr/chatgpt-langchain/blob/main/chapter4/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUj2y-stek1W"
      },
      "source": [
        "# 4. 랭체인 기초"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩에 보안 비밀을 등록한 경우\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "-tQ8X_2ntqQO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3cSlNQV9ZBB"
      },
      "source": [
        "## 4-1 랭체인 개요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WqgjYwQUemjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122d72e8-8a64-4b8c-ca17-96b198f0f52a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.1.14 in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
            "Requirement already satisfied: openai==1.14.3 in /usr/local/lib/python3.10/dist-packages (1.14.3)\n",
            "Requirement already satisfied: langchain-openai==0.1.1 in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (0.0.31)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (0.1.38)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (0.1.38)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.14) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.14.3) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.14.3) (4.10.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.1) (0.6.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.14.3) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.14.3) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.14.3) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.14.3) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.14.3) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.14) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.37->langchain==0.1.14) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.14) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.14) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.14) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.14) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.14) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.1) (2023.12.25)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.14 openai==1.14.3 langchain-openai==0.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMModXMNetUP"
      },
      "source": [
        "## 4-2 Language models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3elDRjh9jVa"
      },
      "source": [
        "### LLMs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
        "result = llm.invoke(\"자기소개를 해주세요.\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fey169JhGa0H",
        "outputId": "872c7e01-00f5-4f71-d905-cfbfa2849918"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "안녕하세요. 저는 김지원입니다. 저는 대학교에서 경영학을 전공하고 현재는 기업에서 인사담당으로 일하고 있습니다. 저는 새로운 도전을 좋아하고 적극적으로 일에 임하는 성격을 가지고 있습니다. 또한 문제 해결능력과 커뮤니케이션 능력이 뛰어나며 적응력이 높은 편입니다. 제가 맡은 일에 대해서는 책임감을 가지고 최선을 다하며, 항상 성장하고 발전하는 것을 목표로 삼고 있습니다. 또한 다양한 사람들과 함께 일하며 새로운 아이디어를 공유하고 발전시키는 것을 즐기는 편입니다. 이러한 제\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvqkiiI-9mI9"
      },
      "source": [
        "### Chat models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fLI_K6YIewJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18264ae-1a44-4cd4-fff2-a3ae6be38ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "네, 앞서 말씀하신대로 존 씨 맞으시죠?\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"안녕하세요! 저는 존이라고 합니다!\"),\n",
        "    AIMessage(content=\"안녕하세요, 존 씨! 어떻게 도와드릴까요?\"),\n",
        "    HumanMessage(content= \"제 이름을 아세요?\")\n",
        "]\n",
        "\n",
        "result = chat.invoke(messages)\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLRYe3Ec9qAO"
      },
      "source": [
        "### Callback을 이용한 스트리밍"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WLxGXw7zgXlR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "144e9cc3-600e-49b2-f1a7-a09a8b6db04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요! 저는 인공지능 언어모델을 담당하는 AI입니다. 자연어 처리 기술을 활용하여 사용자들과 대화를 나누고 다양한 정보를 제공하는 것을 목표로 하고 있습니다. 질문이나 이야기를 주시면 최대한 도와드리겠습니다. 함께 즐거운 시간 보내요!"
          ]
        }
      ],
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()],\n",
        ")\n",
        "\n",
        "messages = [HumanMessage(content=\"자기소개를 해주세요\")]\n",
        "result = chat.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRH_6qBQnEjZ"
      },
      "source": [
        "## 4-3 Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJvnkWfA9tIT"
      },
      "source": [
        "### Prompt templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XLfdULPOjUDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "088b84a3-5863-46a2-e652-ed33f72475be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "다음 요리의 레시피를 생각해 주세요.\n",
            "\n",
            "요리: 카레\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "다음 요리의 레시피를 생각해 주세요.\n",
        "\n",
        "요리: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   input_variables=[\"dish\"],\n",
        "   template=template,\n",
        ")\n",
        "\n",
        "result = prompt.format(dish=\"카레\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIYyxXfj9viN"
      },
      "source": [
        "### ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cUvu-76mnWBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16420735-798f-4c64-e61f-7976485e9a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SystemMessage(content='당신은 영국 요리 전문가입니다.'), HumanMessage(content='다음 요리의 레시피를 생각해 주세요.\\n\\n요리: 고기감자조림')]\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\"당신은 {country} 요리 전문가입니다.\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"다음 요리의 레시피를 생각해 주세요.\\n\\n요리: {dish}\")\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_prompt(country=\"영국\", dish=\"고기감자조림\").to_messages()\n",
        "\n",
        "print(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5-WsdEpEsNta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1535f31b-adfb-4b44-db9a-e7ea3f6848fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "고기감자조림 레시피:\n",
            "\n",
            "재료:\n",
            "- 쇠고기 (양지머리 또는 등심) 300g\n",
            "- 감자 2개\n",
            "- 양파 1개\n",
            "- 당근 1/2개\n",
            "- 대파 1대\n",
            "- 마늘 3쪽\n",
            "- 고추 1개 (선택사항)\n",
            "- 간장 3큰술\n",
            "- 설탕 1큰술\n",
            "- 다진 마늘 1큰술\n",
            "- 참기름 1큰술\n",
            "- 식용유 2큰술\n",
            "- 물 1컵\n",
            "\n",
            "조리법:\n",
            "1. 쇠고기는 한입 크기로 썰어 소금과 후추로 조미한 후 냉장고에서 30분 정도 숙성시킨다.\n",
            "2. 감자, 양파, 당근은 깍뚝썰기로 썰고 대파는 어슷썰기로 준비한다.\n",
            "3. 팬에 식용유를 두르고 다진 마늘을 볶다가 쇠고기를 넣고 익힌다.\n",
            "4. 쇠고기가 익으면 감자, 양파, 당근을 넣고 볶는다.\n",
            "5. 간장, 설탕, 물을 넣고 뚜껑을 덮어 중불에서 10분 정도 끓인다.\n",
            "6. 대파와 고추를 넣고 한번 더 볶아 마무리한다.\n",
            "7. 참기름을 뿌려 완성한다.\n",
            "\n",
            "맛있는 고기감자조림이 완성되었습니다. 식사하실 때 즐겁게 드세요!\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "result = chat.invoke(messages)\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9SAbwnNwFQq"
      },
      "source": [
        "## 4-4 Output Parsers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gUPEasNNBlP"
      },
      "source": [
        "### PydanticOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FEkmkZixwEdi"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "   ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "   steps: list[str] = Field(description=\"steps to make the dish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aosaD-s-wExZ"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Recipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "blhjs33M-AHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2891798f-2db8-4163-a4c9-2a2079dd92e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "21EfCn8b-AFY"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"다음 요리의 레시피를 생각해 주세요.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "요리: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   template=template,\n",
        "   input_variables=[\"dish\"],\n",
        "   partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z5Y0KvYk-ADU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2032c25c-beba-4412-c836-02b9e94376d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다음 요리의 레시피를 생각해 주세요.\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"steps\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Steps\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"steps\"]}\n",
            "```\n",
            "\n",
            "요리: 카레\n",
            "\n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = prompt.format(dish=\"카레\")\n",
        "\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5gQjKsGy9__B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35d58b1-83ec-4549-89bf-9a16e8b5eac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ingredients\": [\n",
            "    \"카레 가루\",\n",
            "    \"양파\",\n",
            "    \"감자\",\n",
            "    \"당근\",\n",
            "    \"고기 (소고기, 닭고기, 돼지고기 중 선택)\",\n",
            "    \"물\",\n",
            "    \"식용유\",\n",
            "    \"소금\",\n",
            "    \"후추\"\n",
            "  ],\n",
            "  \"steps\": [\n",
            "    \"양파, 감자, 당근을 깍뚝 썰어준다.\",\n",
            "    \"고기를 잘게 썰어준다.\",\n",
            "    \"냄비에 식용유를 두르고 양파를 볶다가 고기를 넣고 익힌다.\",\n",
            "    \"감자와 당근을 넣고 볶아준다.\",\n",
            "    \"물을 부어 카레 가루를 넣고 끓인다.\",\n",
            "    \"소금과 후추로 간을 해준다.\",\n",
            "    \"쌀밥과 함께 내놓아 맛있게 즐긴다.\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "messages = [HumanMessage(content=formatted_prompt)]\n",
        "output = chat.invoke(messages)\n",
        "\n",
        "print(output.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZY4cBqNZ9_1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee2d550-4d99-4535-8547-4f8c85cca66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Recipe'>\n",
            "ingredients=['카레 가루', '양파', '감자', '당근', '고기 (소고기, 닭고기, 돼지고기 중 선택)', '물', '식용유', '소금', '후추'] steps=['양파, 감자, 당근을 깍뚝 썰어준다.', '고기를 잘게 썰어준다.', '냄비에 식용유를 두르고 양파를 볶다가 고기를 넣고 익힌다.', '감자와 당근을 넣고 볶아준다.', '물을 부어 카레 가루를 넣고 끓인다.', '소금과 후추로 간을 해준다.', '쌀밥과 함께 내놓아 맛있게 즐긴다.']\n"
          ]
        }
      ],
      "source": [
        "recipe = parser.parse(output.content)\n",
        "print(type(recipe))\n",
        "print(recipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUVnoApz-v9O"
      },
      "source": [
        "## 4-5 Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU0czqQn-xgL"
      },
      "source": [
        "### LLMChain―PromptTemplate, Language model, OutputParser를 연결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bpPIlgjpyroZ"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "   ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "   steps: list[str] = Field(description=\"steps to make the dish\")\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "template = \"\"\"다음 요리의 레시피를 생각해 주세요.\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "요리: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   template=template,\n",
        "   input_variables=[\"dish\"],\n",
        "   partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jys6cH41C4NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c241bc-f21a-4b4a-d434-70c818762713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'dish': '카레', 'text': Recipe(ingredients=['카레 가루', '양파', '감자', '당근', '고기 (소고기, 닭고기, 돼지고기 중 선택)', '물', '식용유', '소금', '후추'], steps=['1. 양파, 감자, 당근을 깍뚝 썰어준다.', '2. 냄비에 식용유를 두르고 양파를 볶아준다.', '3. 고기를 넣고 익힌다.', '4. 감자와 당근을 넣고 볶아준다.', '5. 물을 부어 카레 가루를 넣고 끓인다.', '6. 소금과 후추로 간을 맞춰준다.', '7. 밥 위에 카레를 올려 맛있게 즐긴다.'])}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(prompt=prompt, llm=chat, output_parser=output_parser)\n",
        "\n",
        "recipe = chain.invoke(\"카레\")\n",
        "\n",
        "print(type(recipe))\n",
        "print(recipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCt-YzvX-z4k"
      },
      "source": [
        "### SimpleSequentialChain ― Chain과 Chain을 연결"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PcL-GWtO-0v4"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "cot_template = \"\"\"다음 질문에 답하세요.\n",
        "\n",
        "질문: {question}\n",
        "\n",
        "단계별로 생각해 봅시다.\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = PromptTemplate(\n",
        "   input_variables=[\"question\"],\n",
        "   template=cot_template,\n",
        ")\n",
        "\n",
        "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TGTWjr3rKBCX"
      },
      "outputs": [],
      "source": [
        "summarize_template = \"\"\"다음 문장을 결론만 간단히 요약하세요.\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rYGaG5tuKEVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65d7bae-b7db-493d-e22c-2b825a4f26f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 10개의 사과가 남았다.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "cot_summarize_chain = SimpleSequentialChain(chains=[cot_chain, summarize_chain])\n",
        "\n",
        "result = cot_summarize_chain.invoke(\n",
        "   \"저는 시장에 가서 사과 10개를 샀습니다. 이웃에게 2개, 수리공에게 2개를 주었습니다. 그런 다음에 사과 5개를 더 사서 1개를 먹었습니다. 남은 개수는 몇 개인가요?\"\n",
        ")\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfF-e9njsnY-"
      },
      "source": [
        "위 입력은 [Chain-of-Thought Prompting | Prompt Engineering Guide](https://www.promptingguide.ai/techniques/cot)에서 인용했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jpeYc6ARqBz"
      },
      "source": [
        "## 4-6 Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yOh1zrMRrbn"
      },
      "source": [
        "### ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WugAW9-LKGJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d35e3d-e102-412c-951c-226dd2ce0930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: 안녕하세요. 저는 존이라고 합니다!\n",
            "AI: 안녕하세요, 존님! 저는 인공지능 대화형 도우미입니다. 어떻게 도와드릴까요?\n",
            "You: 제 이름을 아세요?\n",
            "AI: 네, 방금 말씀하셨듯이 당신의 이름은 존님이라고 알고 있습니다.\n",
            "You: 끝\n",
            "(대화 종료)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "\n",
        "    if user_message == \"끝\":\n",
        "        print(\"(대화 종료)\")\n",
        "        break\n",
        "\n",
        "    ai_message = conversation.invoke(input=user_message)[\"response\"]\n",
        "    print(f\"AI: {ai_message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP7tlg1XsnY_"
      },
      "source": [
        "### (칼럼) Chat models에서 Memory를 사용할 때 주의할 점"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zoEzLBS7KLmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4bba1a-3b81-40ef-c01e-71495dc62522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "네, 앞서 말씀해주신대로 존 님의 이름을 알고 있습니다. 어떻게 도와드릴까요?\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"안녕하세요. 저는 존이라고 합니다!\"),\n",
        "    AIMessage(content=\"안녕하세요, 존 님! 어떻게 도와드릴까요?\"),\n",
        "    HumanMessage(content= \"제 이름을 아세요?\")\n",
        "]\n",
        "\n",
        "result = chat.invoke(messages)\n",
        "print(result.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}